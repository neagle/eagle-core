#!/bin/bash

# Get color variables
source "${BASH_SOURCE%/*}/_colors"

_exit() {
	_display "Exiting." $RED
	exit 1
}

# Delete secrets nicely so that we don't get errors if they don't exist
_delete_secret() {
	if kubectl get secret $1 -n $2 &>/dev/null; then
		_display "Resetting existing secret: $1..."
		kubectl delete secret $1 -n $2
	fi
}

## Meet the various prerequisites
prerequisites="true"
mustBeSet() {
	v=$1
	if [ -z "${!v}" ]; then
		_display "${v} must be set." $YELLOW
		prerequisites="false"
	fi
}
mustHaveProgram() {
	p=$1
	if ! [ -x "$(command -v $p)" ]; then
		_display "${p} must be installed and in the path." $YELLOW
		prerequisites="false"
	fi
}

mustWaitForDashboardPod() {
	echo -n -e "${YELLOW}Waiting for greymatter dashboard pod to be ready${NC}"
	while true; do
		POD=$(kubectl get pods -n greymatter -l greymatter.io/cluster=dashboard -o jsonpath="{.items[0].metadata.name}")
		STATUS=$(kubectl get pods $POD -n greymatter -o jsonpath="{.status.conditions[?(@.type=='Ready')].status}")
		if [ "$STATUS" == "True" ]; then
			echo -e "\nDashboard pod is ready."
			break
		else
			echo -n -e "${CYAN}.${NC}"
			sleep 10
		fi
	done
}

mustWaitForDashboardService() {
	echo -n -e "${YELLOW}Waiting for greymatter dashboard service to be ready${NC}"
	while true; do
		# Check if the service is available by trying to curl it
		# We use the `-s` option for silent mode, `-f` to return non-zero status for server errors (4xx and 5xx)
		# and `-o /dev/null` to not output the content to the console
		if curl -ksfo /dev/null http://localhost:10908; then
			echo -e "\nDashboard is up!"
			break
		else
			echo -n -e "${CYAN}.${NC}"
			sleep 10
		fi
	done
}

mustWaitForEdge() {
	# initialize waiting message
	echo -n -e "${YELLOW}Waiting for edge to be ready${NC}"

	# initialize attempt counter
	attempts=0
	max_attempts=20

	# loop until we get an external IP
	external_ip=""
	while [ -z "$external_ip" ] && [ $attempts -lt $max_attempts ]; do
		# append another dot, increment attempts, wait a bit
		echo -n -e "${CYAN}.${NC}"
		attempts=$((attempts + 1))
		sleep 10
		# try to fetch external IP again
		external_ip=$(kubectl get svc edge -n greymatter --template="{{range .status.loadBalancer.ingress}}{{.ip}}{{end}}" 2>/dev/null)
	done

	# check if the loop exited due to max attempts
	if [ $attempts -eq $max_attempts ]; then
		local OPERATOR_POD_NAME=$(kubectl get pods -n gm-operator --no-headers -o custom-columns=":metadata.name" | grep "greymatter-operator-" | head -1)

		echo "\n\n"
		_display "Something might be wrong. Check your operator logs and events." $VIOLET
		_display "kubectl logs -n gm-operator $OPERATOR_POD_NAME" $ORANGE
		_display "kubectl events -n gm-operator" $ORANGE
		return 1
	fi

	# print final success message
	echo -e "\nEnd point ready: $external_ip"
	_display "End point ready" $external_ip
	export endpoint=$external_ip

	# For the moment, use this tip from Joel to get rid of the error with audits
	# Might need to fine-tune where this is, just needs the greymatter namespace to be created, which is done by operator
	_delete_secret greymatter-audits greymatter
	kubectl create secret generic greymatter-audits --from-literal=elasticsearch_username="" --from-literal=elasticsearch_password="" -n greymatter

	local ip=$(kubectl get service edge -n greymatter --template="{{(index .status.loadBalancer.ingress 0).ip}}")
	local port=$(kubectl get service edge -n greymatter --template="{{(index .spec.ports 0).port}}")

	mustWaitForDashboardPod
	mustWaitForDashboardService
	_display "Dashboard URL: http://localhost:${port}" $GREEN
}

## Meet the prerequisites before going in and changing anything
mustBeSet "GREYMATTER_REGISTRY"
mustBeSet "GREYMATTER_REGISTRY_USERNAME"
mustBeSet "GREYMATTER_REGISTRY_PASSWORD"
mustHaveProgram k3d
mustHaveProgram kubectl
mustHaveProgram ssh-keyscan
mustHaveProgram ssh-keygen
mustHaveProgram perl

## Make the new cluster in the target namespace. Avoid 6999 and 443 port conflicts
if [ "$prerequisites" != "true" ]; then
	_display "Prerequisites not met." $RED
	_exit
fi

: ${PRIVATE_KEY:=$(echo ~/).ssh/id_rsa}
# Check if the file exists and is a regular file. If not, exit with an error message.
if [[ ! -f $PRIVATE_KEY ]]; then
	_display "The private key file $PRIVATE_KEY does not exist. Please provide a valid path via the PRIVATE_KEY environment variable if you have a private key with a different name or at a different location."
	_exit
fi
_display "PRIVATE_KEY" $PRIVATE_KEY $BLUE $YELLOW

# Generate manifests
_display "Generating manifests..."
# Remove previous generated manifests
rm -rf "$(dirname "$0")"/../generated-manifests
"$(dirname "$0")"/generate-manifests >/dev/null 2>&1

# Add in the git url
GIT_URL=$(git config --get remote.origin.url | perl -pe 's/[.@]/\\$&/g')
perl -pi -e "s#git\@github\.com:<your-org>/greymatter-core\.git#${GIT_URL}#g" generated-manifests/*.yaml
BRANCH=$(git branch --show)
perl -pi -e "s#  - main#  - ${BRANCH}#g" generated-manifests/*.yaml

# Check if the private key has a passphrase
if ! ssh-keygen -y -P "" -f "$PRIVATE_KEY" >/dev/null 2>&1; then
	# If the PRIVATE_KEY_PASSWORD environment variable is not set or is empty
	if [[ -z "${PRIVATE_KEY_PASSWORD}" ]]; then
		echo "It looks like $PRIVATE_KEY requires a passphrase. Please set PRIVATE_KEY_PASSWORD."
		_exit
	else
		if ! command -v yq &>/dev/null; then
			_display "You must install the program yq to dynamically insert your PRIVATE_KEY_PASSWORD into the generated manifests." $YELLOW
			_exit
		fi
		yq -i e 'select(.spec.template.metadata.labels.name == "greymatter-operator").spec.template.spec.containers[0].args += ["-sshPrivateKeyPassword", "'"$PRIVATE_KEY_PASSWORD"'"]' generated-manifests/operator.yaml
	fi
fi

_display "CLUSTER CREATE"
export MY_CLUSTER=gmdata
k3d cluster delete $MY_CLUSTER
k3d cluster create $MY_CLUSTER --api-port 6999 --port 443:443@loadbalancer --port 10908:10908@loadbalancer --port 10809:10809@loadbalancer
_display "CLUSTER kubeconfig START"
sleep 5 # is there something we can wait on?
export KUBECONFIG="$(k3d kubeconfig write $MY_CLUSTER)"
_display "CLUSTER kubeconfig STOP"
kubectl config use-context k3d-$MY_CLUSTER

kubectl create namespace gm-operator

# discard output to stderr
known_hosts=$(ssh-keyscan github.com 2>/dev/null)

_delete_secret "server-ca"
if [[ -f ../eagle-gmd/certs/gmdata_ca_cert.pem ]]
then
	echo "using ca cert generated by tenant"
else
	( cd ../eagle-gmd/certs; ./mkcerts )
fi
kubectl create secret generic server-ca \
	--from-file=server-ca.crt=../eagle-gmd/certs/gmdata_ca_cert.pem \
	--from-file=server.crt=../eagle-gmd/certs/gmdata_edge_cert.pem \
	--from-file=server.key=../eagle-gmd/certs/gmdata_edge_key.pem \
        -n gm-operator

_delete_secret greymatter-core-repo gm-operator
kubectl create secret generic greymatter-core-repo \
	--from-file=ssh-private-key=$PRIVATE_KEY \
	--from-literal=known_hosts="$known_hosts" \
	-n gm-operator

_display "Create jfrog secret"
_delete_secret greymatter-image-pull gm-operator
kubectl create secret docker-registry greymatter-image-pull \
	--docker-server=$GREYMATTER_REGISTRY \
	--docker-username=$GREYMATTER_REGISTRY_USERNAME \
	--docker-password=$GREYMATTER_REGISTRY_PASSWORD \
	--docker-email=$GREYMATTER_REGISTRY_USERNAME \
	-n gm-operator

# Note: there used to be a sleep 30 command in here, and it was probably put
# in for a reason. But when I remove it, everything seems to work fine. Keep
# an eye on this and, if we can see a reason that it's sometimes necessary,
# figure out a way to wait on the specific thing we need.

_display "Apply the operator..."
kubectl apply -f ./generated-manifests/operator-spire.yaml
mustWaitForEdge

# If the environment variable PROJECT_TENANT is defined, then apply the tenant
if [[ -n "${PROJECT_TENANT}" ]]; then
	_display "PROJECT_TENANT" $PROJECT_TENANT
	_display "Apply the tenant..."
	(
		cd $PROJECT_TENANT
		./scripts/setup
	)
fi
